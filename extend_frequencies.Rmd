---
title: "Classify Frequencies - Extensions"
author: "Andreas M. Brandmaier, Elisabeth Riha"
date: "20.01.2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup

```{r fireup, echo=TRUE}
setwd("/home/elli/Documents/Remote/Github/bnnlib/vignettes")

dyn.load(paste("../bnnlib", .Platform$dynlib.ext, sep=""))
source("../bnnlib.R")
cacheMetaData(1)

library(gridExtra)
source("../R/toSequence.R")

library(ggplot2)
```

## Generate Frequency Data

We generate data from an oscillator that switches between three different frequencies. The switches occur randomly at a chance of 1% (and a switch may choose the identical frequency). We generate multiple sequences each with a length of 1000.

```{r generate}
set.seed(123535)

# simulate frequency data
freqs = c(50, 77, 91, 100)

# function that simulates frequencies 
sim.frequencies <- function(freqs, ts.len = 1000, num.seqs = 4) {
 seqset <- SequenceSet() 
 num.freqs <- length(freqs)
 for (j in 1:num.seqs) {
    x <- 1:ts.len
    y<-rep(NA, ts.len)
    truth <- matrix(0, nrow=ts.len, ncol=length(freqs))
    freq <- sample(freqs,1)
    for (i in 1:ts.len) {
      y[i] <- sin(x[i]*freq)
      if (runif(1)>.99) {
        freq <- sample(freqs,1)
      }
      truth[i, which(freqs==freq)] <- 1
    }
    seqdf <- data.frame(y, truth)
    seq <- toSequence(seqdf, 1, 2:(1+num.freqs))
    SequenceSet_add_copy_of_sequence(seqset, seq)
  }
  return(seqset)
}

seqset <- sim.frequencies(freqs, num.seqs = 8)
testset <- sim.frequencies(freqs)
```

Plot data from training set:

```{r plot}
plotinput <- function(index) {
seq1<-SequenceSet_get(seqset,index-1)
ln <- Sequence_size(seq1)
vals <-  rep(NA, ln)
  for (i in 1:ln) {
		outp <- Sequence_get_input(seq1, i-1)
		vals[i] <- .Call('R_swig_toValue',  outp, package="bnnlib") 
  }
plot(vals, type="l")
}

par(mfrow=c(2,2))
plotinput(1)
plotinput(2)
plotinput(3)
plotinput(4)
```

We set up a recurrent neural network with a winner-takes-all output function that normalizes the sum of outputs to one and guarantuees that each output is non-negative. The network has a total of three output nodes, one for each possible frequency and learns to encode/predict the probability with which each of the frequencies is "on". Ideally, the network should always select one of the outputs to be close to "1" and the others "0" since this is a noise-free environment. From this task, it is not possible to infer the occurence of a switch, so there will always be some prediction error when a switch occurs but it should be possible to quickly stabilize to the correct prediction.

```{r network}
in_size <- 1
out_size <- length(freqs)
TANH_NODE <- 1

# iterations in training
iter = c(500)

nr_layers <- c(1, 2, 3, 4)
# network/networks is of class _p_Network
networks = list() 
trainers = list()
values = list()
xs = list()

# empty df with nr of rows = nr_layers x length(values) 
plotdat = data.frame(matrix(NA, nrow = iter[1]*length(nr_layers), ncol = 3))
colnames(plotdat) = c("condition", "x", "y")
plotdat$x <- rep(seq(1:iter), length(nr_layers))

# faster: fill data in list and create dataframe from list afterwards
# mydata <- list()
# matr <- matrix(NA, nrow = iter[1]*length(nr_layers), ncol = 3)

for (i in seq_len(NROW(nr_layers))) {
  networks[[i]] = NetworkFactory_createRecurrentWTANetwork(in_size=in_size,
                                                          hid_type=TANH_NODE,
                                                          num_layers=nr_layers[i],
                                                          layer_sizes=c(8,8),
                                                          out_size=out_size);
  # initialize trainers and set learning rate 
  trainers[[i]] = ImprovedRPropTrainer(networks[[i]]);
  Trainer_learning_rate_set(self = trainers[[i]], s_learning_rate = 0.0001 )
  
  # train the networks 
  Trainer_train2(trainers[[i]], seqset, iterations = iter)
  setClass('_p_ImprovedRPropTrainer', contains=c('ExternalReference','_p_Trainer'))
  Trainer_add_abort_criterion__SWIG_0(self = trainers[[i]], 
                                      ConvergenceCriterion(0.01), 
                                      steps=10)
  
  # create dfs to plot training error lateron 
  xs[[i]] <- Trainer_error_train_get(trainers[[i]])
  # vector of length 500
	values[[i]] <- .Call('R_swig_toValue', xs[[i]], package="bnnlib") 
	# groups with different conditions  
	plotdat$condition[((i*iter + 1)-iter):(i*iter)] <- rep(seq_len(NROW(nr_layers))[i], iter)
}

# fill values in dataframe for creating plots 
plotdat$y <- cbind(unlist(values))

# dataframe with dimensions: nr of conditions X LÃ¤nge der Steps 
# mit NAs?

plotdat <- as.data.frame(plotdat)
plotdat$condition <- as.factor(plotdat$condition)
```

```{r}
# joint plot of x & y 
# group = condition 
# facet_wrap()

library(ggplot2)
plot1 <- ggplot(data=as.data.frame(plotdat), aes(x=x, y=y, colour=condition)) +
  geom_line() +
  theme_minimal() +
  ggtitle("Trainingsset Error")

plot1
```

```{r}
# test case without loop 
network2 = NetworkFactory_createRecurrentWTANetwork(in_size=in_size, 
                                                   hid_type=TANH_NODE, 
                                                   num_layers=2,
                                                   layer_sizes=c(8,8),  
                                                   out_size=out_size);
# initialize trainers and set learning rate 
trainer2 = ImprovedRPropTrainer(network2);
Trainer_learning_rate_set(self = trainer2, s_learning_rate = 0.0001 )
  
# train the networks 
Trainer_train2(trainer2, seqset, iterations = iter[1])
setClass('_p_ImprovedRPropTrainer', contains=c('ExternalReference','_p_Trainer'))
Trainer_add_abort_criterion__SWIG_0(self = trainer2, 
                                    ConvergenceCriterion(0.01), 
                                    steps=10)
  
# create dfs to plot training error lateron 
xs2 <- Trainer_error_train_get(trainer2)
# vector of length 500
values2 <- .Call('R_swig_toValue', xs2, package="bnnlib") 

library(ggplot2)
ggplot(data.frame(x=1:length(values2),values2),aes(x=x,y=values2))+
  geom_line()+
  theme_minimal()+
  ggtitle("Trainingset Error: 2 Hidden Layers")

################################################

network3 = NetworkFactory_createRecurrentWTANetwork(in_size=in_size, 
                                                   hid_type=TANH_NODE, 
                                                   num_layers=3,
                                                   layer_sizes=c(8,8),  
                                                   out_size=out_size);
# initialize trainers and set learning rate 
trainer3 = ImprovedRPropTrainer(network3);
Trainer_learning_rate_set(self = trainer3, s_learning_rate = 0.0001 )
  
# train the networks 
Trainer_train2(trainer3, seqset, iterations = iter[1])
setClass('_p_ImprovedRPropTrainer', contains=c('ExternalReference','_p_Trainer'))
Trainer_add_abort_criterion__SWIG_0(self = trainer3, 
                                    ConvergenceCriterion(0.01), 
                                    steps=10)
  
# create dfs to plot training error lateron 
x3 <- Trainer_error_train_get(trainer3)
# vector of length 500
values3 <- .Call('R_swig_toValue', x3, package="bnnlib") 

library(ggplot2)
ggplot(data.frame(x=1:length(values3),values3),aes(x=x,y=values3))+
  geom_line()+
  theme_minimal()+
  ggtitle("Trainingset Error: 3 Hidden Layers")
```

```{r}
# joint plot of x & y 
# group = condition 
# facet_wrap()

library(ggplot2)
plot1 <- ggplot(data=as.data.frame(plotdat), aes(x=x, y=y, group=condition, colour=condition)) +
  geom_line() +
  theme_minimal() +
  ggtitle("Trainingsset Error")

plot1
# # create plots 
	# plots[[i]] <- ggplot(data.frame(x=1:length(values[[i]]),values[[i]]),aes(x=x,y=values[[i]]))+
	#   geom_line()+theme_minimal()+ggtitle(paste0("Trainingset Error:", i ,"Hidden Layers"))

# gen_plots <- function(data, values) {
#   ggplot(data, aes(x=x,y=values)) +
# 	  geom_line()+theme_minimal()+ggtitle(paste0("Trainingset Error", i, "Hidden Layers"))
# 
# }
# plots <- lapply(, gen_plots, data = data.frame(x=1:length(values),values))

# freie Parameter 
# mit lapply 
```

```{r}
# Test Example

nr <- c(1,2,3)
itera <- c(10)
datar <- data.frame(matrix(NA, nrow = itera*length(nr), ncol = 3))
colnames(datar) <- c("condi", "x", "y")
datar$x <- rep(1:itera, length(nr))

listi <- list()

for (i in seq_len(NROW(nr))) {
  listi[[i]] <- rep(i+1, itera)
  # for (j in seq_len(NROW(1:itera))) {
  # data$y[j] <- listi[[i]][j]
  # }
}

datar$y <- cbind(unlist(listi))

# datar$y[1:10] <- listi[[1]]
# datar$y[11:20] <- listi[[2]]
# datar$y[21:30] <- listi[[3]]
```

Train the network

```{r training}
# initialize trainers and set learning rate 
trainer2 = ImprovedRPropTrainer(networks[[1]]);
Trainer_learning_rate_set(trainer2, 0.0001 )

setClass('_p_ImprovedRPropTrainer', contains = c('ExternalReference','_p_Trainer'))
Trainer_add_abort_criterion__SWIG_0(trainer2, ConvergenceCriterion(0.01),10 )
setClass('_p_ImprovedRPropTrainer', contains = c('ExternalReference','_p_Trainer'))
Trainer_add_abort_criterion__SWIG_0(trainer5, ConvergenceCriterion(0.01),10 )
```

Plot the training error.

```{r plottraining}
x2 <- Trainer_error_train_get(trainer2)
x5 <- Trainer_error_train_get(trainer5)

library(ggplot2)
	values <- .Call('R_swig_toValue', x2, package="bnnlib") 
	ggplot(data.frame(x=1:length(values),values),aes(x=x,y=values))+geom_line()+
	  theme_minimal()+ggtitle("Trainingset Error: 2 Hidden Layers")

library(ggplot2)
	values <- .Call('R_swig_toValue', x5, package="bnnlib") 
	ggplot(data.frame(x=1:length(values),values),aes(x=x,y=values))+geom_line()+
	  theme_minimal()+ggtitle("Trainingset Error: 5 Hidden Layers")
```

## Predictions

Investigate the predictions on the training set. Extract predictions and sequence information and store in matrices.

```{r}
setwd("/home/elli/Documents/Remote/Github/bnnlib/vignettes")
source("../R/plotPredictions.R")
seq1<-SequenceSet_get(seqset,0)
plotPredictions(network2, seq1)
seq1<-SequenceSet_get(seqset,0)
plotPredictions(network5, seq1)# second network does not seem to get predictions
```

Same on test set

```{r test}
setwd("/home/elli/Documents/Remote/Github/bnnlib/vignettes")
source("../R/plotPredictions.R")
seq1 <- SequenceSet_get(testset, 0)
plotPredictions(network2, seq1)
seq1 <- SequenceSet_get(testset, 0)
plotPredictions(network5, seq1)# second network does not seem to get predictions
```